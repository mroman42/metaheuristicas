#+TITLE: Práctica 2.b
#+SUBTITLE: Técnicas de búsqueda basadas en poblaciones para el problema del aprendizaje de pesos en características (APC).
#+AUTHOR: Mario Román García
#+LANGUAGE: es

#+latex_header: \usepackage[spanish]{babel}\decimalpoint
#+latex_header: \usepackage{amsmath}
#+latex_header: \usepackage{algorithm}
#+latex_header: \usepackage{tikz}
#+latex_header: \usepackage{pgfplots}\pgfplotsset{compat=1.15} 
#+latex_header: \usepackage[noend]{algpseudocode}
#+latex_header: \usepackage{pdflscape}
#+latex_header: \usepackage[a4paper]{geometry}

#+OPTIONS: toc:nil tasks:nil
#+LATEX_HEADER_EXTRA: \usepackage{wallpaper}\ThisULCornerWallPaper{1}{ugrA4.pdf}


* Datos de portada                                                   :ignore:
# Portada con el número y título de la práctica, el curso académico, el
# nombre del problema escogido, los algoritmos considerados; el nombre,
# DNI y dirección e-mail del estudiante, y su grupo y horario de
# prácticas.

 * DNI: XXXXXXXXZ
 * Email: mromang08@correo.ugr.es
 * Grupo 1 (Lunes de 17:30 a 19:30)
 * Algoritmos: AGE-{BLX,CA}, AGG-{BLX,CA}, AM-{10,0.1,mej}.
 * Metaheurísticas, 2017-2018.

* Índice                                                             :ignore:
#+latex: \newpage
#+TOC: headlines 2
#+latex: \newpage
* Formulación del problema
# Máximo 1 página
Trataremos un problema de *aprendizaje de pesos en características*
(APC), consistente en la optimización de la simplicidad y precisión de
un clasificador 1-NN; es decir, un clasificador que asigna a cada instancia
la clase de la instancia más cercana a él, para una distancia euclídea modificada
por un vector de pesos. Así, cada solución del problema vendrá dada por un
vector de valores reales $w_i \in [0,1]$ para $1 \leq i \leq n$, donde $n$ es el número
de características que tiene el problema. La bondad de un clasificador
de este tipo sobre un conjunto de evaluación $T$ vendrá determinada como
\[
F(\left\{ w_i \right\}) = \alpha \mathrm{tasaClas}\left\{ w_i \right\} + (1 - \alpha) \mathrm{tasaRed}\left\{ w_i \right\}.
\]
En esta fórmula, $\mathit{tasaClas}$ debe ser entendida como la *precisión* del
algoritmo, midiendo el porcentaje de aciertos del clasificador en el
conjunto de evaluación $T$. Por otro lado, $\mathit{tasaRed}$ debe ser entendido
como la *simplicidad* de la solución, que mide el número de pesos $w_i$ que
quedan por debajo de $0.2$, y que consecuentemente no se tienen en cuenta al
calcular las distancias. En nuestro caso tenemos determinado un valor de
$\alpha = 0.5$ que equipara ambas métricas.

En resumen, el algoritmo deberá tomar un conjunto de datos y producir
un clasificador 1-NN con unos pesos asignados a las características que
sean sencillos, en el sentido de usar el mínimo número de características,
y que sean precisos, en cuanto a su habilidad para clasificar instancias
fuera del conjunto de entrenamiento.

* Aplicación de algoritmos
:PROPERTIES:
:ID:       1260d567-03c8-4b79-9549-4bbfdf0c22e9
:END:
# Máximo 4 páginas

** Esquema de representación de soluciones
Como hemos tratado anteriormente, una solución del problema viene dada
por un vector de pesos. Nuestra representación específica de una solución
vendrá dada por una lista de valores reales.

\[
\left\{ w_i \right\}_{0 \leq i \leq n} = \left( w_1,w_2,\dots,w_n \right)
\]

Donde $n$ será el número de características que tenga nuestro conjunto
de datos y $w_i$. En nuestra implementación específica, los pesos
vendrán dados por un vector contiguo en memoria de valores en coma
flotante de precisión doble en 64 bits; para facilitar su tratamiento,
en ciertos algoritmos se traducirán a listas enlazadas, pero su
interpretación matemática será siempre constante y se describe
explícitamente en la función objetivo.

** Clasificador 1-NN, función objetivo
Se define la *distancia con pesos* $\left\{ w_i \right\}$ entre dos vectores $t$ y $s$
como
\[
\mathrm{dist}(w,t,s) = \sum_{i=0}^n w_i(t_i - s_i)^2.
\]
Y nuestro clasificador $\mathrm{kNN}$ para unos pesos $\left\{ w_i \right\}$ consiste en devolver
la clase del punto que minimiza la distancia. Es decir, es una implementación
de un clasificador 1NN, que para cada instancia devuelve la clase
de su vecino más cercano. En el caso de la función objetivo, al no
tener un conjunto de test separado, usamos la técnica de /leave-one-out/.

\begin{algorithm}
\small
\caption{Función objetivo (w : Pesos, T : Training)}
\begin{algorithmic}[1]

\State $\mathrm{Obj}(w,T) = \alpha \cdot \mathrm{precision}(w,T) + (1-\alpha) \mathrm{simplicity}(w)$
\State $\mathrm{TasaRed}(w) = \mathrm{length} [x < 0.2 \mid x \in w] / \mathrm{length}\ w$
\State $\mathrm{TasaClas}(w,T) = \sum_{t \in T} (\mathrm{knn}(w,T - t,t) == s.Clase) / \mathrm{length}\ s$
\State $\mathrm{knn}(w,T,t) = (\mathrm{minimizador}_{t' \in T} (\mathrm{dist^2}(\mathrm{trunca}(w),t',t))).Clase$
\State $\mathrm{trunca}(w) = \left\{ 0 \mbox{ si } w_i < 0.2;\quad w_i \mbox{ en otro caso }\mid w_i \in w \right\}$
\end{algorithmic}
\end{algorithm}

En el código original esta función objetivo aparecerá implementada dos
veces: una vez para el puntuador de los algoritmos y otra vez para la
función objetivo. Esta duplicación tiene como ventaja que separa
completamente las partes de evaluación del código de los algoritmos,
reduciendo la posibilidad de error. Además,

 * la implementación para evaluación es corta y es más fácil de
   verificar que está escrita correctamente;
 * mientras que la implementación de la función objetivo está
   fuertemente optimizada, usando paralelismo, pero en caso de que
   tuviera cualquier error, eso no se vería reflejado en las
   puntuaciones de los algoritmos.

Es importante notar que la formulación original del problema no asume
que todas las variables sean reales, y en el caso en el que son discretas
asume una distancia de Hamming que simplemente indica si las dos características
son exactamente iguales.
\[\mathrm{dist}(a,b) = \delta_{ab} = \left\{\begin{array}{cl}
1 & \mbox{ si } a = b \\
0 & \mbox{ si } a \neq b \\
\end{array}\right.\]

En los conjuntos de datos que trataremos en este análisis, tenemos de
hecho que todas las características vienen dadas por reales, y nuestra
implementación, aunque sería fácilmente extensible, no tratará el otro
caso explícitamente.

** Generación de soluciones aleatorias
La generación de una *solución aleatoria inicial* se realiza llamando
repetidas veces a las librerías del lenguaje cite:MonadRandom. Estas proporcionan
funciones que nos permiten clacular listas potencialmente infinitas
de números reales distribuidos uniformemente en el intervalo $[0,1]$.
Además, usamos replicamos el proceso aleatorio con mónadas para poder generar varios individuos
cuidando que sean muestras independientes bajo el mismo generador aleatorio.

\begin{algorithm}
\small
\caption{Solución inicial (t : Training)}
\begin{algorithmic}[1]

\State $\begin{aligned}\mathrm{solInicial}(t) &= \mbox{tomaLos } (\mathrm{nAttr}(t)) \mbox{ primerosDe }\ \mathrm{aleatorioUniforme} (0.0,1.0)
\end{aligned}$
\State $\begin{aligned}\mathrm{PoblInicial}(n = 30, t) &= \mbox{replica } n\ \mathrm{solInicial}
\end{aligned}$

\end{algorithmic}
\end{algorithm}

* Pseudocódigo de selección, cruce y mutación
** Torneo binario
Un torneo binario es un proceso aleatorio que genera un individuo o
desde una población de soluciones. La población de soluciones llega
a este punto del algoritmo en una estructura ordenada por bondad
de solución basada en árboles binarios balanceados por tamaño
(véase cite:DataSet y cite:SetsInFP), por lo que simplemente
debemos elegir dos índices y tomar el mayor. El conjunto de entrenamiento
no se usa explícitamente en el algoritmo pero es una dependencia
necesaria para haber calculado previamente la bondad de los elementos
de la población.

\begin{algorithm}
\small
\caption{Torneo binario (p : Población, T : Training)}
\begin{algorithmic}[1]

\State $x = \mathrm{randomEntre}(0, \mathrm{size}(p)-1)$
\State $y = \mathrm{randomEntre}(0, \mathrm{size}(p)-1)$
\State $\mathrm{torneo}(p) = p[\mathrm{max}\ x\ y]$

\end{algorithmic}
\end{algorithm}

En el código implementamos además variantes que realizan varios torneos
binarios seguidos para usarlas directamente en los algoritmos.

** Cruce aritmético
El cruce aritmético de dos soluciones es una operación componente
a componente que devuelve el centro de gravedad n-dimensional de
los dos padres. Es una operación determinista que sólo genera un
hijo.

\begin{algorithm}
\small
\caption{Cruce aritmético (a : Individuo, b : Individuo)}
\begin{algorithmic}[1]

\State $media(x,y) = (x+y)/2.0$
\State $ca(a,b) = \mathrm{componenteAComponente}\ \mathrm{media}\ a\ b$

\end{algorithmic}
\end{algorithm}

** Cruce BLX
El cruce BLX sí es no determinista y sí nos permitirá obtener dos
hijos desde una sola pareja de padres. Nuestro código genera un solo
hijo y simplemente repite (de nuevo usando internamente la estructura
de mónadas) el procedimiento para asegurarse la independencia de los dos hijos.

\begin{algorithm}
\small
\caption{Cruce BLX (a : Individuo, b : Individuo)}
\begin{algorithmic}[1]

\State $blx2(a,b) = \mathrm{replica}\ 2\ \mathrm{blx}(a,b)$
\State $blx(a,b) = \mathrm{componenteAComponente}\ \mathrm{blxComp}(a,b)$
\State $blxComp(x,y) = \mathrm{aleatorioUniformeEn}\ \mathrm{intervalo}(x,y)$
\State $intervalo(x,y) = [0,1] \cap [\min(x,y) - \alpha|x-y|, \max(x,y) + \alpha|x-y|]$

\end{algorithmic}
\end{algorithm}

En nuestro caso, además, prepararemos el código para tratar
uniformemente los dos operadores de cruce distintos, haciendo que cada
uno devuelva una lista con uno y dos hijos y dejando que cada
algoritmo que los trate estos dos casos directamente.

** Mutación
La mutación, en su versión más común, procede directamente del
operador de generación de vecinos de la búsqueda local que
implementamos en la primera práctica y que simplemente añade una
cantidad aleatoria a uno de los pesos de la solución. En ocasiones nos
interesará mutar cada gen de un individuo con probabilidad 0.001 y que
la simulación de este proceso aleatorio sea precisa; este será el caso
en el modelo estacionario.

\begin{algorithm}
\small
\caption{Mutación (s : Solución)}
\begin{algorithmic}[1]

\State $Muta(s) = \mathrm{truncaEntre0y1}\
\mathrm{map}\ (\lambda x. \mbox{if }rand() < 0.001 \mbox{ then } x + rand()\mbox{ else }x)$
\end{algorithmic}
\end{algorithm}

Mientras que en otras ocasiones nos interesará aplicar un número
fijo de mutaciones aleatorias sobre la población completa en lugar
de generar un número aleatorio y comprobar si mutamos o no cada uno
de los genes. Este será el caso en el modelo generacional.

\begin{algorithm}
\small
\caption{MutaPoblación (p : Población, n : Nº mutaciones)}
\begin{algorithmic}[1]

\State $Muta(p) = \mathrm{replica}\ n\ MutaUnaVez(p[i],j), \mbox{ para } i = rand(), j = rand()$
\State $MutaUnaVezEn(s,j) = \mathrm{truncaEntre0y1}\ 
\mathrm{map}\ (\lambda (x,i). x + \delta_{ij} \varepsilon)\ (\mathrm{indexa}\ s)$
\end{algorithmic}
\end{algorithm}

En esos casos controlaremos el número de mutaciones totales para que
se correspondan a las que deberían producirse en caso de que usáramos
la esperanza matemática para calcular el número de mutaciones.

* Pseudocódigo del esquema de evolución y reemplazamiento
En general, nuestro algoritmo genético repite una subrutina denominada
/paso generacional/ que se corresponderá con un cruce y sustitución en
el modelo estacionario y con el avance de una generación en la
evolución generacional. El criterio de parada no se determina por el
número de generación sino por el número de evaluaciones de la función
objetivo, que se almacena con la estructura de datos del algoritmo. 

\begin{algorithm}
\small
\caption{EsquemaEvolutivo (pasoEv : Subrutina)}
\begin{algorithmic}[1]

\State $pobl \gets \mathrm{poblacionAleatoria}()$
\State $\mathrm{iteraMientras}(evaluaciones > 15000)$
\State $\qquad pasoEv(env)$

\end{algorithmic}
\end{algorithm}

De esta forma podemos modelar las variantes del algoritmo evolutivo
uniformemente. Cuando trabajamos gestionando el generador aleatorio,
podemos escribir en estilo imperativo de programación (esto se conoce
como un "bloque =do=").

** Esquema de evolución estacionario
En el esquema de evolución estacionario, cada iteración hará dos
evaluaciones para los dos nuevos hijos creados y que compiten con los
individuos de la población anterior. Se realizarán los torneos
necesarios para generar 2 hijos (que serán 2 o 4 según el operador de
cruce); luego se mutarán los hijos sin usar la esperanza matemática,
usando el primero de los operadores de mutación que describimos.
Finalmente, se incluyen los hijos en la población y se eliminan los
peores; la estructura de datos ordenada se encargará de esto
automáticamente.

\begin{algorithm}
\small
\caption{EsquemaEstacionario (p : Población, cruza : Operador)}
\begin{algorithmic}[1]

\State $padres \gets \mathrm{torneosBinarios}()$
\State $hijos \gets \mathrm{toma}\ 2\ \mathrm{de}\ \mathrm{cruza}(\mathrm{empareja}(\mathrm{padres}))$
\State $mutados \gets \mathrm{map}\ muta\ hijos$
\State $nuevaPopl \gets \mathrm{insertaYReemplazaEn}(p,mutados)$
\State $contadorEvaluaciones \gets +2$

\end{algorithmic}
\end{algorithm}

Finalmente, el /emparejamiento/ se hace tomando el primero con el
segundo, tercero con el cuarto, y así sucesivamente. En el caso en
el que se necesitaran más parejas, se vuelve a empezar con la lista en el
segundo elemento para emparejar el segundo con el tercero y así sucesivamente.

** Esquema de evolución generacional
Las iteraciones del algoritmo generacional generan 21 hijos nuevos;
las parejas necesarias para ello (que serán el doble cuando estemos
usando un operador de cruce de un solo hijo como el cruce aritmético)
se obtendrán generando al principio una nueva población por torneo
binario de 30 padres y luego usando el 70% para generar hijos.
Luego aplicaremos de nuevo mutación a toda la población usando esta
vez la esperanza matemática y acabaremos incluyendo el mejor de la
generación anterior en la nueva población.

\begin{algorithm}
\small
\caption{EsquemaGeneracional (p : Población, cruza : Operador)}
\begin{algorithmic}[1]

\State $mejor \gets \mathrm{max}(p)$
\State $padres \gets \mathrm{torneosBinarios}()$
\State $hijos \gets \mathrm{cruza}(\mathrm{empareja}(70\% \mbox{ de los } padres))$
\State $npopl \gets \mathrm{toma}\ 30 \mbox{ de } padresNoCruzados + hijos + padresNoSubstituidos$
\State $npopl \gets \mathrm{reemplaza}(mejor)\ \$\ \mathrm{muta}(npopl)$
\State $contadorEvaluaciones \gets nº(hijos)+nº(padresMutados)$

\end{algorithmic}
\end{algorithm}

** Reemplazamiento
Explícitamente, el reemplazamiento en la población se realiza
insertando y eliminando el mínimo en la estructura
ordenada que describimos anteriormente.

\begin{algorithm}
\small
\caption{Reemplazamiento (p : Población, h : individuo)}
\begin{algorithmic}[1]

\State $reemplaza(p,h) = (borraMínimo \circ inserta(h))\ p$
\end{algorithmic}
\end{algorithm}

En cuanto al reemplazamiento en la selección del torneo binario,
se ha implementado con y sin reemplazamiento (simplemente filtrando
índices duplicados), pero se usa con reemplazamiento en su versión
más simple tal y como indica la práctica. Esto podría hacer que
alguna vez tocaran aleatoriamente los dos padres iguales.

* Pseudocódigo de integración de algoritmos meméticos
El haber escrito el esquema evolutivo independiente de la estrategia
evolutiva o el operador de cruce concreto que usemos nos permite ahora
introducir los algoritmos meméticos con una variación pequeña del
código de esquema evolutivo.  Nótese que la población aquí considerada
será de 10 en lugar de 30.

\begin{algorithm}
\small
\caption{EsquemaMemético (pasoEv : Subrutina)}
\begin{algorithmic}[1]

\State $pobl \gets \mathrm{poblacionAleatoria}(size = 10)$
\State $\mathrm{iteraMientras}(evaluaciones > 15000)$
\State $\qquad \mathrm{Si}\ generacion \% 10 == 0 \mbox{ entonces } pasoM(ev) \mbox{ si no } pasoEv(env)$

\end{algorithmic}
\end{algorithm}

Aquí, /generación/, que no debe confundirse con el número de
evaluaciones, cuenta el número de iteraciones del paso evolutivo, ya
sea generacional o estacionario.

** Versiones del algoritmo memético
Sobre este esqueleto se integran las distintas versiones del algoritmo
memético. Todas ellas se empiezan basando en una función que aplica
búsqueda local sobre los $n$ mejores individuos de la población, pero
con una probabilidad $p$ sobre cada uno de ellos. Si llamamos a esta
función $pBusqueda(n,p)$, las tres versiones del algoritmo memético
buscadas pueden obtenerse como

 1. $pBusqueda(size(popl),1)$, aplicará búsqueda sobre todos los
    cromosomas de la población;

 2. $pBusqueda(size(popl),0.1)$, aplicará búsqueda para cada cromosoma
    de un conjunto en el que se selecciona cada uno con probabilidad
    $0.1$;

 3. $pBusqueda(size(popl)/10,1)$, aplicará búsqueda sobre los $0.1$ mejores
    cromosomas de la población.

El código de esta función central incrementará el contador de
evaluaciones según las necesite. Nótese que aunque la búsqueda local
siempre debe parar cuando se hayan evaluado $2m$ vecinos distintos en
cada ejecución, donde $m$ es el número de atributos, el número total de
evaluaciones dependerá de la selección aleatoria de cromosomas y no
será fijo en general.

\begin{algorithm}
\small
\caption{pBusqueda (n : nº mejores, p : probabilidad, popl : Población)}
\begin{algorithmic}[1]

\State $(noseleccionados , seleccionados) \gets (\mathrm{escogelosNmejores}(n, popl) , \mathrm{resto}(n,popl))$
\State $nuevos \gets map\ localSearch\ seleccionados$
\State $\mathrm{return}\ nuevos \cup noseleccionados$

\end{algorithmic}
\end{algorithm}

Finalmente, esta $pBusqueda$ es la que se usa como implementación
de $pasoM$, variando los parámetros en cada uno de los casos.

** Cálculo de diversidad
En la sección sobre experimentos describiremos una nueva versión del
algoritmo memético que estará basada en experimentar con la diversidad.
Lo importante para llegar a esos resultados será el código que calcule
la diversidad de una población y la muestre por una salida de error que
nos permita guardarla sin afectar a la ejecución del resto del algoritmo.

Tal y como detallaremos después, la diversidad la mediremos como
\[
\mathrm{diversidad}(Popl) =
\sum_{a,b \in \mathrm{Popl}} \mathrm{dist(a,b)},
\]
y quedará implementada en el siguiente código.

\begin{algorithm}
\small
\caption{diversidad (popl : Población)}
\begin{algorithmic}[1]

\State $EuclDistance(a,b) = (\sum_{x \in a, y \in b} (x-y)^2)^{1/2}$
\State $Diversidad(popl) = \sum_{a,b \in popl} \mathrm{dist}(a,b)$
\State $ImprimeDiversidad = \mathrm{imprime}(generacionActual + "," + Diversidad(popl))$

\end{algorithmic}
\end{algorithm}

* Procedimiento considerado, manual de usuario
Al igual que en la primera práctica, se usa *Haskell* cite:haskell98 y
paralelismo con cite:DataVector. El proceso de validación y generación
de los resultados se hace reproducible con cite:GNUmake y se encuentra
en el archivo =makefile=, en el que se declaran las semillas de aleatoriedad
(=$SEEDn=) que son las que se envían a los distintos algoritmos.

Además de los ejecutables de validación =bin/fivefold= y =bin/scorer=,
así como los algoritmos de la primera práctica, presentamos los ejecutables
nuevos de algoritmos genéticos:

 * =bin/Ageca=, implementación del algoritmo genético estacionario con
   cruce aritmético;
 * =bin/Ageblx=, implementación del algoritmo genético estacionario con
   cruce BLX;
 * =bin/Aggca=, implementación del algoritmo genético generacional con
   cruce aritmético;
 * =bin/Aggblx=, implementación del algoritmo genético generacional con
   cruce BLX;

y los ejecutables de algoritmos meméticos:

 * =bin/AmAll=, implementación del algoritmo memético sobre genético
   generacional con cruce BLX, aplicando búsqueda cada 10 generaciones
   sobre todos los los cromosomas (AM-10,1.0); 
 * =bin/AmProb=, implementación del algoritmo memético sobre genético
   generacional con cruce BLX, aplicando búsqueda cada 10 generaciones
   sobre todos los los cromosomas pero con probabilidad 0.1 (AM-10,0.1);
 * =bin/AmBest=, implementación del algoritmo memético sobre genético
   generacional con cruce BLX, aplicando búsqueda cada 10 generaciones
   sobre el 10% de los mejores (AM-10,0.1mej);
 * =bin/AmBest=, implementación del algoritmo memético sobre genético
   generacional con cruce BLX, aplicando búsqueda cada 10 generaciones
   sobre todos los cromosomas, incrementando la frecuencia de
   mutaciones y cambiando el operador BLX para introducir más
   diversidad (AM-div); una justificación de este algoritmo adicional
   se presenta en la sección de experimentos.

Todas las implementaciones reciben como argumento de línea de comandos
una semilla aleatoria y leen por la entrada estándar un conjunto de
entrenamiento; acabarán devolviendo una solución por salida estándar.

Para el resto de detalles de ejecución nos referimos a la primera
práctica.

* Experimentos y análisis de los resultados
Nuestros algoritmos reciben varios parámetros que fijamos en el
código. Explícitamente, el tamaño de población en los genéticos es 30,
mientras que es 10 en los meméticos. La probabilidad de cruce será de
1 en el estacionario y 0.7 en el generacional (nótese que en el
generacional usaremos la esperanza matemática). La probabilidad de
mutación será siempre del 0.001 (en el generacional usaremos de nuevo
la esperanza matemática). En la mutación, tomamos $\sigma = 0.3$ al igual que
en la primera práctica y para el BLX tomamos $\alpha = 0.3$. El criterio de parada
es siempre de 15000 evaluaciones de la función objetivo.

** AGE-CA
Los resultados de nuestra primera versión de un algoritmo genético son
comparables con los resultados de la búsqueda local, siendo la única
diferencia un incremento en tiempo derivado de que, aunque nuestro
criterio de parada nos sigue asegurando la misma cantidad de
evaluaciones de la función objetivo, la gestión de la población
consume ahora mucho más tiempo.

\begin{table}[!ht]
\scriptsize
\centering
  \label{multiprogram}
  \input{../data/Ageca.tex}
  \caption{Algoritmo AGE-CA en el problema del APC}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[scale=0.40]{../data/ageca-parkinsons-best.png}
\caption{Puntuación del mejor individuo en el tiempo en Parkinsons bajo AGE-CA.}
\end{figure}

** AGE-BLX
El cambio a un operador de cruce BLX parece dar mejores
resultados. Una hipótesis es que la falta de diversidad estaba
limitando innecesariamente nuestro algoritmo, haciendo mucho más lento
el saltar de una solución a otra mejor y atascándose innecesariamente
en extremos locales. Esta hipótesis podemos comprobarla con los
gráficos que añadimos, que muestran cómo varía la mejor solución
encontrada conforme avanza el algoritmo. Destacamos que este nuevo
operador introduce una componente de aleatoriedad y que permite la
exploración más allá de la recta que incluye a las dos soluciones,
ambas características que no poseía el cruce aritmético.

\begin{table}[!ht]
\scriptsize
\centering
  \caption{Algoritmo AGE-BLX en el problema del APC}
  \label{multiprogram}
  \input{../data/Ageblx.tex}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[scale=0.40]{../data/ageblx-parkinsons-best.png}
\caption{Puntuación del mejor individuo en el tiempo en Parkinsons bajo AGE-BLX.}
\end{figure}

En este caso, obtenemos un algoritmo que mejora ligeramente en
resultados a la búsqueda local, indicando que este es un buen camino
a seguir.

** AGG-CA
El cambio a generacional da resultados consistentemente peores que el
uso de estacionarios. Nuestra hipótesis aquí es que esto esté causado
porque, al seleccionar una nueva población a cada generación con
torneos que pueden repetir a los elementos de la élite a cada paso, la
convergencia sea más rápida a un extremo local de lo que sería
deseable.

\begin{table}[!ht]
\scriptsize
\centering
  \caption{Algoritmo AGG-CA en el problema del APC}
  \label{multiprogram}
  \input{../data/Aggca.tex}
\end{table}

** AGG-BLX
En la implementación de un algoritmo genético generacional con
operador de cruce BLX obtenemos resultados ligeramente mejores que con
su equivalente con el cruce aritmético.  De nuevo el uso de un
operador de cruce incrementando la posibilidad de exploración mejora
los resultados. Esta mejora es la que nos lleva a implementar los
algoritmos meméticos sobre este operador de cruce en lugar de sobre el
cruce aritmético.

\begin{table}[!ht]
\scriptsize
\centering
  \caption{Algoritmo AGG-BLX en el problema del APC}
  \label{multiprogram}
  \input{../data/Aggblx.tex}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[scale=0.40]{../data/aggblx-parkinsons-diversity.png}
\caption{Diversidad de la población en el tiempo en Parkinsons bajo AGG-BLX.}
\end{figure}

Confirmamos además que tenemos una gran falta de diversidad en nuestro
algoritmo, podemos definir una medida de diversidad como la suma de
distancias entre los distintos individuos.

\[
\mathrm{diversidad}(Popl) =
\sum_{a,b \in \mathrm{Popl}} \mathrm{dist(a,b)}.
\]

** AM-(10,1.0)
Los algoritmos meméticos representan una importante mejora frente a
sus contrapartes genéticas. En particular, en este caso implementamos
un algoritmo memético que cada 10 generaciones aplica búsqueda local
a toda la población, y que usa el esquema generacional con un operador
de cruce BLX. La elección de BLX la justificamos en la superioridad que
ha mostrado en los experimentos anteriores. 

\begin{table}[!ht]
\scriptsize
\centering
  \caption{Algoritmo AM-(10,1.0) en el problema del APC}
  \label{multiprogram}
  \input{../data/AmAll.tex}
\end{table}

En este caso podemos comprobar que una de las causas por las que debe
estar mejorando el caso genético es debido a que la diversidad se está
incrementando. Tomaremos esta idea como inspiración para implementar
una versión propia del algoritmo memético: idealmente nos gustaría poder
mantener un cierto nivel de diversidad durante la ejecución completa
del algoritmo.

\begin{figure}[H]
\centering
\includegraphics[scale=0.40]{../data/amall-parkinsons-diversity.png}
\caption{Diversidad de la población en el tiempo en Parkinsons bajo AM-(10,1.0).}
\end{figure}

En cualquier caso, hemos obtenido un algoritmo basado sobre un
generacional pero con resultados mucho mejores que él. Esto nos
confirma que aunque los generacionales estaban funcionando de
manera pobre, el aplicar búsquedas locales que concreten el
extremo local al que se acerca cada individuo mejora los resultados
notablemente.

** AM-(10,0.1)
Esta versión de un algoritmo memético vuelve a utilizar el esquema
generacional evolutivo y a elegir el operador de cruce BLX. Sin
embargo, en lugar de aplicar la búsqueda local sobre cada uno de los
individuos de la población, elegimos de manera aleatoria, con probabilidad
0.1, si aplicarla sobre cada uno de los individuos.

\begin{table}[!ht]
\scriptsize
\centering
  \caption{Algoritmo AM-(10,0.1) en el problema del APC}
  \label{multiprogram}
  \input{../data/AmProb.tex}
\end{table}

Los resultados son ligeramente peores, y aunque no parecen
suficientemente fuertes como para no atribuirlos a la aleatoriedad,
podríamos intuir que gastar menos búsquedas locales no está ayudando
al algoritmo memético.

** AM-(10,0.1mej)
La última versión del algoritmo memético es similar a la anterior pero
aplica de manera más selecta la optimización por búsqueda local solo
en la mejor de las instancias.

\begin{table}[!ht]
\scriptsize
\centering
  \caption{Algoritmo AM-(10,0.1mej) en el problema del APC}
  \label{multiprogram}
  \input{../data/AmBest.tex}
\end{table}

Aunque los resultados vuelven a ser una variación de los anteriores,
es muy reseñable que en este caso, donde solo aplicamos búsqueda local
sobre el mejor, obtengamos resultados similares. Esto sugiere que si
necesitáramos reducir las evaluaciones de la función objetivo,
podríamos intentar reducir el número de individuos en los que se
aplica la búsqueda local sin incurrir necesariamente en pérdidas
de calidad importantes.

** AM-div
Nuestra propuesta para solucionar el problema de la falta de diversidad
pasa por cambiar el parámetro del cruce BLX a un valor ligeramente mayor
($\alpha = 0.5$), intentando así que los intervalos en los que se pueden mover
los valores del cruce sean más amplios; e incrementar hasta 0.01 la posibilidad
de mutación.

\begin{table}[!ht]
\scriptsize
\centering
  \caption{Algoritmo AM-(10,0.1mej) en el problema del APC}
  \label{multiprogram}
  \input{../data/AmNew.tex}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[scale=0.40]{../data/amnew-parkinsons-diversity.png}
\caption{Diversidad de la población en el tiempo en Parkinsons bajo AM-div.}
\end{figure}

Hemos obtenido un algoritmo tan bueno como el mejor de los meméticos y
que incluso lo mejora en el conjunto de datos "Spectf". El valor
exacto de los dos ajustes de parámetros lo hemos obtenido
empíricamente buscando que facilitaran mantener una ligera diversidad
hasta el final de la ejecución; pero una propuesta futura podría ser
automatizar esta elección de parámetros tras comprobar cómo funciona
sobre varios conjuntos de datos y usando la medida de diversidad
propuesta como criterio para la elección.

** Resultados globales y comparación

\begin{table}[!ht]
\scriptsize
\centering
  \caption{Resultados globales en el problema del APC}
  \label{multiprogram}
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c|}
\cline{2-13}
&\multicolumn{4}{|c|}{Ozone} & \multicolumn{4}{|c|}{Parkinsons} & \multicolumn{4}{|c|}{Spectf}\\
\cline{2-13}
& clas & red & Agr. & T(s)
& clas & red & Agr. & T(s)
& clas & red & Agr. & T(s) \\
\hline
\multicolumn{1}{|c|}{1NN}&0.816&0.000&0.408&0.032&0.783&0.000&0.391&0.008&0.774&0.000&0.387&0.016\\
\multicolumn{1}{|c|}{RELIEF}&0.819&0.014&0.416&0.118&0.794&0.000&0.397&0.024&0.767&0.000&0.383&0.055\\
\multicolumn{1}{|c|}{BL}&0.628&0.969&0.799&15.354&0.391&0.973&0.682&1.192&0.622&0.954&0.788&9.458\\
\multicolumn{1}{|c|}{BL2}&0.738&0.800&0.769&13.177&0.655&0.909&0.782&0.898&0.768&0.855&0.811&7.488\\
\multicolumn{1}{|c|}{AGE-CA}&0.747&0.703&0.725&57.608&0.744&0.764&0.754&16.566&0.802&0.668&0.735&54.469\\
\multicolumn{1}{|c|}{AGE-BLX}&0.744&0.831&0.787&53.886&0.786&0.882&0.834&17.787&0.768&0.791&0.779&36.351\\
\multicolumn{1}{|c|}{AGG-CA}&0.738&0.645&0.691&32.838&0.785&0.382&0.583&9.434&0.761&0.627&0.694&30.513\\
\multicolumn{1}{|c|}{AGG-BLX}&0.763&0.642&0.702&59.889&0.745&0.536&0.641&16.059&0.794&0.605&0.699&53.961\\
\multicolumn{1}{|c|}{AM-(10,1.0)}&0.769&0.817&0.793&57.391&0.809&0.882&0.845&16.333&0.734&0.791&0.763&57.729\\
\multicolumn{1}{|c|}{AM-(10,0.1)}&0.775&0.767&0.771&60.870&0.779&0.864&0.821&19.237&0.738&0.805&0.771&53.216\\
\multicolumn{1}{|c|}{AM-(10,0.1mej)}&0.713&0.786&0.749&59.689&0.798&0.882&0.840&18.029&0.753&0.759&0.756&54.846\\
\multicolumn{1}{|c|}{AM-div}&0.775&0.811&0.793&63.017&0.729&0.891&0.810&19.188&0.760&0.827&0.794&59.235\\
\hline
\end{tabular}
\end{table}

Aunque los algoritmos de referencia (1NN y RELIEF) han quedado
claramente superados por todos los algoritmos presentados después,
las búsquedas locales (en las dos versiones que propusimos) son
perfectamente comparables e incluso superan en algunos casos a los
algoritmos genéticos generacionales.  Sin embargo, estos prueban
su utilidad cuando se mezclan en algoritmos genéticos, que obtienen
los mejores resultados hasta el momento. Podemos analizar de esta
situación que la búsqueda local es un buen procedimiento para aplicar
a un algoritmo que, pese a encontrar buenas soluciones, parece no ser
capaz de alcanzar un mínimo local consistentemente.

Los algoritmos estacionarios, por otro lado, quizá porque no varían
la población completa a cada paso y van sustituyendo los hijos por
los peores de la población, manteniendo a los mejores padres, alcanzan
resultados mucho mejores. Esto justifica la idea del elitismo en los
generacionales, y que quizá podríamos reforzarla con más medidas orientadas
a mantener a los mejores incluso después de ser cruzados.

Finalmente, los algoritmos meméticos sólo han planteado el problema de
la diversidad, que quitaba utilidad a las últimas iteraciones del
algoritmo. Sin este problema, son consistentemente sobre todos los
conjuntos de datos los mejores algoritmos que hemos implementado.

** Conclusiones
Los algoritmos meméticos son los que mejor han funcionado hasta el
momento, y además han dado una utilidad a las versiones generacionales
de los algoritmos genéticos, que sin usar meméticos eran peores incluso
que nuestra implementación de la búsqueda local (tanto con el operador
inicial como con el nuevo operador diseñado en la primera práctica).

La importancia de alcanzar equilibrio entre exploración y explotación
se ha manifestado en los resultados de estas ejecuciones y ha guiado
los últimos experimentos. Un problema común en los algoritmos ha sido
la falta de diversidad, algunos pasando demasiado tiempo en un
conjunto muy pequeño de las soluciones. Las correcciones en esta
dirección han mejorado los resultados.

* Referencias                                                                               :ignore:
bibliographystyle:alpha
bibliography:Bibliography.bib
